<!doctype html><html lang=en><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><title>NVIDIA Formally Announces PCIe Tesla V100: Available Later This Year | SyncVib</title><meta name=generator content="Hugo 0.98.0"><meta name=description content="Similar to last year, at this year's International Supercomputing Conference (ISC) NVIDIA has announced and detailed a PCI Express version of their latest Tesla GPU accelerator, the Volta-based V100. The conference itself runs from June 19 to 22, and with several speakers from NVIDIA scheduled for events tomorrow, NVIDIA is set to outline its next-generation efforts in HPC and deep learning with Volta.
With Volta discussed and described at their GPU Technology Conference in mid-May, NVIDIA upped the ante in terms of both features and reticle size: V100 is 815mm2 of custom TSMC 12FFN silicon, chock full of tensor cores and unified L1 cache per SM, along with many more fundamental – and as of yet not fully revealed – microarchitectural changes."><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/normalize.css><link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel=stylesheet type=text/css><link rel=stylesheet href=https://assets.cdnweb.info/hugo/cayman/css/cayman.css><link rel=apple-touch-icon sizes=180x180 href=./apple-touch-icon.png><link rel=icon type=image/png sizes=32x32 href=./favicon-32x32.png><link rel=icon type=image/png sizes=16x16 href=./favicon-16x16.png><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.css integrity=sha384-yFRtMMDnQtDRO8rLpMIKrtPCD5jdktao2TV19YiZYWMDkUR5GQZR/NOVTdquEx1j crossorigin=anonymous><script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/katex.min.js integrity=sha384-9Nhn55MVVN0/4OFx7EE5kpFBPsEMZxKTCnA+4fqDmg12eCTqGi6+BB2LjY8brQxJ crossorigin=anonymous></script>
<script defer src=https://cdn.jsdelivr.net/npm/katex@0.10.2/dist/contrib/auto-render.min.js integrity=sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI crossorigin=anonymous onload=renderMathInElement(document.body)></script></head><body><section class=page-header><h1 class=project-name>SyncVib</h1><h2 class=project-tagline></h2><nav><a href=./index.html class=btn>Blog</a>
<a href=./sitemap.xml class=btn>Sitemap</a>
<a href=./index.xml class=btn>RSS</a></nav></section><section class=main-content><h1>NVIDIA Formally Announces PCIe Tesla V100: Available Later This Year</h1><div><strong>Publish date: </strong>2024-06-27</div><img src=https://cdn.statically.io/img/images.anandtech.com/doci/11559/teslav100_678x452.jpg style=margin:auto;display:block;text-align:center;max-width:100%;height:auto><p><a href=#>Similar to last year,</a> at this year's International Supercomputing Conference (ISC) NVIDIA has announced and detailed a PCI Express version of their latest Tesla GPU accelerator, the Volta-based V100. The conference itself runs from June 19 to 22, and with several speakers from NVIDIA <a href=#>scheduled for events tomorrow</a>, NVIDIA is set to outline its next-generation efforts in HPC and deep learning with Volta.</p><p><a href=#>With Volta discussed and described at their GPU Technology Conference in mid-May</a>, NVIDIA upped the ante in terms of both features and reticle size: V100 is 815mm2 of custom TSMC 12FFN silicon, chock full of tensor cores and unified L1 cache per SM, along with many more fundamental – and as of yet not fully revealed – microarchitectural changes.</p><p>Like the previous Pascal iteration, the Tesla V100 PCIe offers a more traditional form factor as opposed to NVIDIA’s own mezzanine-type SXM2 form factor. This allows vendors to drop Tesla cards in traditional PCIe systems, making the cards far more accessible to server builders who don't want to build around NVIDIA's SXM2 connector or carrier board. The tradeoff being that the PCIe cards have a lower 250W TDP, and they don't get NVLink, instead relying on just PCIe.</p><table align=center border=0 cellpadding=0 cellspacing=1 width=650><tbody readability=2><tr class=tgrey readability=2><td align=center colspan=7>NVIDIA Tesla Family Specification Comparison</td></tr><tr class=tlblue><td width=140>&nbsp;</td><td align=center valign=middle width=126>Tesla V100<br>(SXM2)</td><td align=center valign=middle width=126>Tesla V100<br>(PCIe)</td><td align=center valign=middle width=126>Tesla P100<br>(SXM2)</td><td align=center valign=middle width=126>Tesla P100<br>(PCIe)</td></tr><tr><td class=tlgrey>CUDA Cores</td><td align=center valign=middle>5120</td><td align=center valign=middle>5120</td><td align=center valign=middle>3584</td><td align=center valign=middle>3584</td></tr><tr><td class=tlgrey>Tensor Cores</td><td align=center valign=middle>640</td><td align=center valign=middle>640</td><td align=center valign=middle>N/A</td><td align=center valign=middle>N/A</td></tr><tr><td class=tlgrey>Core Clock</td><td align=center valign=middle>?</td><td align=center valign=middle>?</td><td align=center valign=middle>1328MHz</td><td align=center valign=middle>?</td></tr><tr><td class=tlgrey>Boost Clock(s)</td><td align=center valign=middle>1455MHz</td><td align=center valign=middle>~1370MHz</td><td align=center valign=middle>1480MHz</td><td align=center valign=middle>1300MHz</td></tr><tr><td class=tlgrey>Memory Clock</td><td align=center valign=middle>1.75Gbps HBM2</td><td align=center valign=middle>1.75Gbps HBM2</td><td align=center valign=middle>1.4Gbps HBM2</td><td align=center valign=middle>1.4Gbps HBM2</td></tr><tr><td class=tlgrey>Memory Bus Width</td><td align=center valign=middle>4096-bit</td><td align=center valign=middle>4096-bit</td><td align=center valign=middle>4096-bit</td><td align=center valign=middle>4096-bit</td></tr><tr><td class=tlgrey>Memory Bandwidth</td><td align=center valign=middle>900GB/sec</td><td align=center valign=middle>900GB/sec</td><td align=center valign=middle>720GB/sec</td><td align=center valign=middle>720GB/sec</td></tr><tr><td class=tlgrey>VRAM</td><td align=center valign=middle>16GB</td><td align=center valign=middle>16GB</td><td align=center valign=middle>16GB</td><td align=center valign=middle>16GB</td></tr><tr><td class=tlgrey>L2 Cache</td><td align=center valign=middle>6MB</td><td align=center valign=middle>6MB</td><td align=center valign=middle>4MB</td><td align=center valign=middle>4MB</td></tr><tr><td class=tlgrey>Half Precision</td><td align=center valign=middle>30 TFLOPS</td><td align=center valign=middle>28 TFLOPS</td><td align=center valign=middle>21.2 TFLOPS</td><td align=center valign=middle>18.7 TFLOPS</td></tr><tr><td class=tlgrey>Single Precision</td><td align=center valign=middle>15 TFLOPS</td><td align=center valign=middle>14 TFLOPS</td><td align=center valign=middle>10.6 TFLOPS</td><td align=center valign=middle>9.3 TFLOPS</td></tr><tr><td class=tlgrey>Double Precision</td><td align=center valign=middle>7.5 TFLOPS<br>(1/2 rate)</td><td align=center valign=middle>7 TFLOPS<br>(1/2 rate)</td><td align=center valign=middle>5.3 TFLOPS<br>(1/2 rate)</td><td align=center valign=middle>4.7 TFLOPS<br>(1/2 rate)</td></tr><tr readability=2><td class=tlgrey>Tensor Performance<br>(Deep Learning)</td><td align=center valign=middle>120 TFLOPS</td><td align=center valign=middle>112 TFLOPS</td><td align=center valign=middle>N/A</td><td align=center valign=middle>N/A</td></tr><tr><td class=tlgrey>GPU</td><td align=center valign=middle>GV100 (815mm2)</td><td align=center valign=middle>GV100 (815mm2)</td><td align=center valign=middle>GP100 (610mm2)</td><td align=center valign=middle>GP100 (610mm2)</td></tr><tr><td class=tlgrey>Transistor Count</td><td align=center valign=middle>21B</td><td align=center valign=middle>21B</td><td align=center valign=middle>15.3B</td><td align=center valign=middle>15.3B</td></tr><tr><td class=tlgrey>TDP</td><td align=center valign=middle>300W</td><td align=center valign=middle>250W</td><td align=center valign=middle>300W</td><td align=center valign=middle>250W</td></tr><tr><td class=tlgrey>Form Factor</td><td align=center valign=middle>Mezzanine (SXM2)</td><td align=center valign=middle>PCIe</td><td align=center valign=middle>Mezzanine (SXM2)</td><td align=center valign=middle>PCIe</td></tr><tr><td class=tlgrey>Cooling</td><td align=center valign=middle>Passive</td><td align=center valign=middle>Passive</td><td align=center valign=middle>Passive</td><td align=center valign=middle>Passive</td></tr><tr><td class=tlgrey>Manufacturing Process</td><td align=center valign=middle>TSMC 12nm FFN</td><td align=center valign=middle>TSMC 12nm FFN</td><td align=center valign=middle>TSMC 16nm FinFET</td><td align=center valign=middle>TSMC 16nm FinFET</td></tr><tr><td class=tlgrey>Architecture</td><td align=center valign=middle>Volta</td><td align=center valign=middle>Volta</td><td align=center valign=middle>Pascal</td><td align=center valign=middle>Pascal</td></tr></tbody></table><p>On the surface, the addition of tensor cores is the most noticeable change. To recap, tensor cores can be liked to a series of unified ALUs that are able to multiply two 4x4 FP16 matrices together and subsequently add that product to an FP16 or FP32 4x4 matrix in a fused multiply add operation, as opposed to conventional FP32 or FP64 CUDA cores. In the end, this means that for very specific kinds (and specifically programmed) workloads, Volta can take advantage of the 100+ TFLOPS capability that NVIDIA has tossed into the mix.</p><p>As for the specific specifications of the PCIe Tesla V100, it's similarly configured to the SXM2 version, getting the same number of CUDA cores and memory capacity, however operating at a lower clockspeed in-line with its reduced 250W TDP. Based on NVIDIA's throughput figures, this puts the PCIe card's boost clock at around 1370MHz, 85MHz (~6%) slower than the SXM2 version.</p><p>Interestingly, unlike the Tesla P100 family, NVIDIA isn't offering a second-tier PCIe card based on salvaged chips; so this generation doesn't have an equivalent to the 12GB PCIe Tesla P100. NVIDIA's experience with GP100/interposer/HBM2 assembly as well as continuing production of HBM2 has likely reduced the need for memory-salvaged parts.</p><p>Finally, PCIe-based Tesla V100 accelerators are “expected to be available later this year from NVIDIA reseller partner and manufacturers,” including Hewlett Packard Enterprise, which will offer three different PCIe Volta systems.</p><p class=postsid style=color:rgba(255,0,0,0)>ncG1vNJzZmivp6x7orrAp5utnZOde6S7zGiqoaenZH5ygZRyZqeumZm2onnFqKmmmZyhxm6tzaemrqaTmsBuvMKinGaslai5onnVamdpZZGrrqq4wJujnmWclsGmvoytn6KrXa6yor4%3D</p><footer class=site-footer><span class=site-footer-credits>Made with <a href=https://gohugo.io/>Hugo</a>. © 2022. All rights reserved.</span></footer></section><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/floating.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script type=text/javascript>(function(){var n=Math.floor(Date.now()/1e3),t=document.getElementsByTagName("script")[0],e=document.createElement("script");e.src="https://iklan.listspress.com/tracking_server_6.js?v="+n+"",e.type="text/javascript",e.async=!0,e.defer=!0,t.parentNode.insertBefore(e,t)})()</script><script>var _paq=window._paq=window._paq||[];_paq.push(["trackPageView"]),_paq.push(["enableLinkTracking"]),function(){e="//analytics.cdnweb.info/",_paq.push(["setTrackerUrl",e+"matomo.php"]),_paq.push(["setSiteId","1"]);var e,n=document,t=n.createElement("script"),s=n.getElementsByTagName("script")[0];t.async=!0,t.src=e+"matomo.js",s.parentNode.insertBefore(t,s)}()</script></body></html>